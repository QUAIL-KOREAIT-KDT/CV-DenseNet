{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee362538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [준비 단계]\n",
    "# 의료 데이터셋을 활용하여, DenseNet 모델에 대한 성능을 확인합니다.\n",
    "\n",
    "# >> 비교 모델명        | 역할              | 비교 관점\n",
    "# ResNet-50 (Baseline) | 표준 기준         | 산업계 표준 모델과의 성능 대비 효율성 확인\n",
    "# DenseNet-121 (k=32)  | 효율성 대표\t    | 가장 적은 자원으로 ResNet-50 수준의 성능 달성 여부\n",
    "# DenseNet-169 (k=32)  | 깊이 중심 밀집 연결 | 층을 깊게 쌓았을 때(k=32)의 특징 추출 능력\n",
    "# DenseNet-161 (k=48)  | 너비 중심 밀집 연결 | 성장률(k=48)을 키웠을 때의 성능 극대화 확인\n",
    "\n",
    "# 데이터셋 : The IQ-OTH_NCCD lung cancer dataset (폐암)\n",
    "# https://www.kaggle.com/datasets/hamdallak/the-iqothnccd-lung-cancer-dataset/code\n",
    "\n",
    "# [중요]\n",
    "# 다운 받은 데이터셋을 root 폴더 내 'Data' 폴더에 압축 해제하여 3가지 폴더에 각각 이미지들이 있는 것을 확인할 것.\n",
    "# Data/Benign cases     ; 여기서 직접 폴더명의 오타를 수정한다. Benign -> Benign\n",
    "# Data/Malignant cases\n",
    "# Data/Normal cases\n",
    "\n",
    "# 3가지 클래스 정보\n",
    "# Normal(정상)\n",
    "# Malignant (악성) : 악성 종양, 즉 암. \n",
    "# Benign (양성) : 양성 종양, 즉 암이 아닌 종양."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38185c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 1] 설정 : 시작 import 라이브러리, 환경, 전역 변수\n",
    "#  Epoch, 데이터 분할 비율 등 핵심 설정을 여기서 한 번에 관리합니다.\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "import platform\n",
    "import glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support, accuracy_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "from PIL import Image\n",
    "\n",
    "import gc # [수정] 가비지 컬렉터 임포트 추가\n",
    "\n",
    "# ----------------------------------------\n",
    "# [Global Configurations] 핵심 설정\n",
    "# ----------------------------------------\n",
    "# 1. 학습 관련 변수 (여기서 수정하면 전체 반영)\n",
    "EPOCHS = 15 # min 5 for checking, best 15, max 30\n",
    "\n",
    "# 224x224 인 경우, Batch 32~16 로\n",
    "# 448x448 인 경우, Batch 16~8 로\n",
    "size = 224 \n",
    "BATCH_SIZE = 16 \n",
    "\n",
    "# 2. 데이터 분할 비율 (Train : Valid : Test)\n",
    "# 합이 1.0이 되도록 설정!! train 70% 상황에서 최대한 valid와 test의 균형을 맞춘다.\n",
    "SPLIT_RATIO = (0.7, 0.15, 0.15) \n",
    "\n",
    "# 3. 시드 고정 -> 재현성 확보\n",
    "SEED = 2026\n",
    "\n",
    "# 결과 저장 폴더 정의\n",
    "FOLDERS = {\n",
    "    'visuals': './Result_Visuals_Tight',    # 마스킹 전처리 검증용\n",
    "    'results': './Result_Tight',            # 학습 결과(CSV, Model)\n",
    "    'gradcam': './Result_GradCAM_Tight'     # Grad-CAM 결과 -> 모델의 가중치 영역 시각화 (*.pth 관련)\n",
    "}\n",
    "\n",
    "# 폴더 자동 생성\n",
    "for k, v in FOLDERS.items():\n",
    "    os.makedirs(v, exist_ok=True)\n",
    "\n",
    "# 시드 고정 및 장치 설정\n",
    "def set_seed(seed=SEED):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# 로컬 PC의 GPU 사용 설정\n",
    "set_seed()\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(f\">> 환경 설정 완료.\")\n",
    "print(f\">> Device: {DEVICE}\")\n",
    "print(f\">> Epochs: {EPOCHS}\")\n",
    "print(f\">> Split Ratio: {SPLIT_RATIO}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337194d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 2] 데이터셋 분할 (Data Split)\n",
    "# 설명: 원본 Data 폴더에서 SPLIT_RATIO에 맞춰 Data_split 폴더로 데이터를 무작위 분할합니다.\n",
    "\n",
    "# 원본 데이터 경로 (VSCode 작업 폴더 기준)\n",
    "DATA_DIR = './Data'\n",
    "\n",
    "# 분할된 데이터 저장 경로\n",
    "SPLIT_DIR = './Data_split'\n",
    "\n",
    "def split_dataset():\n",
    "    # 이미 분할된 데이터가 있는지 확인\n",
    "    if os.path.exists(SPLIT_DIR) and len(glob.glob(os.path.join(SPLIT_DIR, 'train', '*', '*'))) > 0:\n",
    "        print(\">> 데이터셋이 이미 분할되어 있습니다. 기존 데이터를 사용합니다.\")\n",
    "        return\n",
    "\n",
    "    print(f\">> 데이터 분할 시작 (비율 {SPLIT_RATIO})...\")\n",
    "    \n",
    "    # 기존 분할 폴더가 있다면 삭제 후 재생성\n",
    "    if os.path.exists(SPLIT_DIR): shutil.rmtree(SPLIT_DIR)\n",
    "    \n",
    "    # 클래스 폴더 읽기\n",
    "    classes = [d for d in os.listdir(DATA_DIR) if os.path.isdir(os.path.join(DATA_DIR, d))]\n",
    "    \n",
    "    for cls in classes:\n",
    "        # Train/Valid/Test 폴더 생성\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            os.makedirs(os.path.join(SPLIT_DIR, split, cls), exist_ok=True)\n",
    "        \n",
    "        # 이미지 파일 리스트 확보\n",
    "        src_path = os.path.join(DATA_DIR, cls)\n",
    "        files = []\n",
    "        for ext in ['*.jpg', '*.png', '*.jpeg', '*.JPG', '*.PNG']:\n",
    "            files.extend(glob.glob(os.path.join(src_path, ext)))\n",
    "            \n",
    "        # 셔플 및 인덱스 계산\n",
    "        random.shuffle(files)\n",
    "        total = len(files)\n",
    "        train_end = int(total * SPLIT_RATIO[0])\n",
    "        valid_end = int(total * (SPLIT_RATIO[0] + SPLIT_RATIO[1]))\n",
    "        \n",
    "        # 파일 복사\n",
    "        for f in files[:train_end]: \n",
    "            shutil.copy(f, os.path.join(SPLIT_DIR, 'train', cls, os.path.basename(f)))\n",
    "        for f in files[train_end:valid_end]: \n",
    "            shutil.copy(f, os.path.join(SPLIT_DIR, 'valid', cls, os.path.basename(f)))\n",
    "        for f in files[valid_end:]: \n",
    "            shutil.copy(f, os.path.join(SPLIT_DIR, 'test', cls, os.path.basename(f)))\n",
    "    \n",
    "    print(\">> 데이터 분할 및 복사 완료.\")\n",
    "\n",
    "split_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d78b8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 3] 정밀 마스킹(몸통 안쪽만) 및 데이터 증강 (반전/회전)\n",
    "# - 각 이미지에 대해서 몸통 바깥쪽의 정보를 배제하고 몸통 안쪽을 학습하기 위해서.\n",
    "# - 경계 안쪽만 남기는 정밀 마스킹을 수행한다.\n",
    "# - 대체로 이미지의 가운데에 위치한 폐 영역에 적용할 적절한 증강 방법으로 반전 및 회전을 적용합니다.\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# --- 1. 정밀 마스킹 함수 (몸통 경계 안쪽만 남기기) ---\n",
    "def preprocess_tight_body(image_path, visualize=False):\n",
    "    # 이미지 로드\n",
    "    stream = open(image_path, \"rb\")\n",
    "    bytes = bytearray(stream.read())\n",
    "    numpy_array = np.asarray(bytes, dtype=np.uint8)\n",
    "    img_array = cv2.imdecode(numpy_array, cv2.IMREAD_UNCHANGED)\n",
    "    stream.close()\n",
    "    \n",
    "    if img_array is None: return None\n",
    "    \n",
    "    # 3채널 보장\n",
    "    if len(img_array.shape) == 2: \n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_GRAY2BGR)\n",
    "    elif img_array.shape[2] == 4: \n",
    "        img_array = cv2.cvtColor(img_array, cv2.COLOR_BGRA2BGR)\n",
    "    \n",
    "    # BGR -> Gray 변환\n",
    "    gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # -------------------------------------------------------------------------\n",
    "    # [핵심 로직] 몸통 경계 찾기 및 배경 제거\n",
    "    # -------------------------------------------------------------------------\n",
    "    # 노이즈 제거 및 이진화 (Otsu Algorithm)\n",
    "    blur = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "    _, thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "    \n",
    "    # 구멍 메우기 (폐 내부의 공기층도 몸통으로 인식되게 함)\n",
    "    kernel = np.ones((5,5), np.uint8)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "    \n",
    "    # 윤곽선(Contour) 찾기\n",
    "    contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # 컨투어를 못 찾으면 원본 반환 (안전장치)\n",
    "    if not contours:\n",
    "        return Image.fromarray(cv2.cvtColor(img_array, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "    # 가장 큰 영역 = 몸통\n",
    "    max_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # 마스크 생성 (몸통 안쪽은 255, 바깥쪽은 0)\n",
    "    mask = np.zeros_like(gray)\n",
    "    cv2.drawContours(mask, [max_contour], -1, 255, -1)\n",
    "    \n",
    "    # 마스킹 적용 (배경을 검은색으로 지움)\n",
    "    masked_img = cv2.bitwise_and(img_array, img_array, mask=mask)\n",
    "    \n",
    "    # 몸통 경계선 시각화용: 노란색 라인 그리기\n",
    "    if visualize:\n",
    "        vis_img = masked_img.copy()\n",
    "        # 노란색 (BGR: 0, 255, 255)\n",
    "        cv2.drawContours(vis_img, [max_contour], -1, (0, 255, 255), 3)\n",
    "        return cv2.cvtColor(vis_img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Crop (몸통 영역만 최대한 타이트하게 잘라냄)\n",
    "    x, y, w, h = cv2.boundingRect(max_contour)\n",
    "\n",
    "    # 약간의 여백(Padding) 추가하여 경계선 정보 보존\n",
    "    pad = 10\n",
    "    x = max(0, x-pad); y = max(0, y-pad)\n",
    "    w = min(img_array.shape[1]-x, w+2*pad)\n",
    "    h = min(img_array.shape[0]-y, h+2*pad)\n",
    "    \n",
    "    final_img = masked_img[y:y+h, x:x+w]\n",
    "    \n",
    "    # BGR -> RGB 변환 후 PIL Image로 반환\n",
    "    return Image.fromarray(cv2.cvtColor(final_img, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "\n",
    "# --- 2. Dataset 정의 ---\n",
    "class TightLungDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.samples = []\n",
    "        if os.path.exists(root_dir):\n",
    "            self.class_names = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n",
    "            self.class_to_idx = {cls: i for i, cls in enumerate(self.class_names)}\n",
    "            \n",
    "            for cls in self.class_names:\n",
    "                cls_folder = os.path.join(root_dir, cls)\n",
    "                for f in os.listdir(cls_folder):\n",
    "                    if f.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                        self.samples.append((os.path.join(cls_folder, f), self.class_to_idx[cls]))\n",
    "        else:\n",
    "            self.class_names = []\n",
    "\n",
    "    def __len__(self): return len(self.samples)\n",
    "    def __getitem__(self, idx):\n",
    "        path, label = self.samples[idx]\n",
    "        # 배경 제거된 몸통 이미지 가져오기\n",
    "        image = preprocess_tight_body(path, visualize=False)\n",
    "        if self.transform: image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "\n",
    "# --- 3. 데이터 증강 및 로더 설정 ---\n",
    "# \n",
    "# 첫 번째 셀 상단에서 조정.\n",
    "# size = 224 # 기본값\n",
    "# BATCH_SIZE = 16 # 기본값\n",
    "\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        \n",
    "        # 폐 영역의 반전과 회전만 적용 (이동 제외)\n",
    "        transforms.RandomHorizontalFlip(p=0.5),      # 좌우 반전\n",
    "        transforms.RandomRotation(degrees=15),       # 회전 (+-15도)\n",
    "        \n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    \n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    'train': DataLoader(TightLungDataset(os.path.join(SPLIT_DIR, 'train'), transform=data_transforms['train']),\n",
    "                        batch_size=BATCH_SIZE, shuffle=True),\n",
    "    'valid': DataLoader(TightLungDataset(os.path.join(SPLIT_DIR, 'valid'), transform=data_transforms['valid']),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False),\n",
    "    'test':  DataLoader(TightLungDataset(os.path.join(SPLIT_DIR, 'test'), transform=data_transforms['test']),\n",
    "                        batch_size=BATCH_SIZE, shuffle=False)\n",
    "}\n",
    "\n",
    "class_names = dataloaders['train'].dataset.class_names\n",
    "print(f\">> Dataset 준비 완료.\")\n",
    "print(f\">> Preprocessing: Tight Body Masking (Background Removed)\")\n",
    "print(f\">> Augmentation: Flip, Rotate(15) ONLY\")\n",
    "print(f\">> Resolution: {size}x{size} | Batch: {BATCH_SIZE}\")\n",
    "\n",
    "\n",
    "# --- [검증] 클래스별 전처리 및 증강 통합 확인 ---\n",
    "def verify_preprocessing_with_aug():\n",
    "    print(\">> [전처리/증강 검증] 클래스별 샘플 확인 (상단: 마스킹, 하단: 증강 적용)...\")\n",
    "    \n",
    "    target_classes = class_names  # ['Normal', 'Malignant', 'Benign']\n",
    "    num_classes = len(target_classes)\n",
    "    \n",
    "    # 증강 시뮬레이션용 transform (ToTensor 제외하고 PIL 상태로 확인)\n",
    "    aug_sim = transforms.Compose([\n",
    "        transforms.Resize((size, size)),\n",
    "        transforms.RandomHorizontalFlip(p=1.0),  # 확인을 위해 강제 반전\n",
    "        transforms.RandomRotation(degrees=15)    # 15도 회전\n",
    "    ])\n",
    "    \n",
    "    fig, axes = plt.subplots(2, num_classes, figsize=(6 * num_classes, 10))\n",
    "    \n",
    "    for i, cls in enumerate(target_classes):\n",
    "        cls_path = os.path.join(SPLIT_DIR, 'test', cls)\n",
    "        if not os.path.exists(cls_path):\n",
    "            cls_path = os.path.join(DATA_DIR, cls)\n",
    "            \n",
    "        img_list = glob.glob(os.path.join(cls_path, '*'))\n",
    "        if not img_list: continue\n",
    "            \n",
    "        sample_path = random.choice(img_list)\n",
    "        \n",
    "        # 1. 배경 제거 및 경계선 시각화 (원본 마스킹 확인)\n",
    "        img_vis = preprocess_tight_body(sample_path, visualize=True)\n",
    "        \n",
    "        # 2. 깨끗한 마스킹 이미지에 증강 적용\n",
    "        img_clean = preprocess_tight_body(sample_path, visualize=False)\n",
    "        img_aug = aug_sim(img_clean)\n",
    "        \n",
    "        fname = os.path.basename(sample_path)\n",
    "        \n",
    "        # 상단: 마스킹 결과 (노란선)\n",
    "        axes[0, i].imshow(img_vis)\n",
    "        axes[0, i].set_title(f\"Class: {cls}\\n[Masking & Crop]\", fontsize=12, fontweight='bold')\n",
    "        axes[0, i].axis('off')\n",
    "        \n",
    "        # 하단: 증강 결과 (반전/회전 적용)\n",
    "        axes[1, i].imshow(img_aug)\n",
    "        axes[1, i].set_title(f\"Augmented (Flip+Rotate)\\n{size}x{size}\", fontsize=12)\n",
    "        axes[1, i].axis('off')\n",
    "        \n",
    "        # 개별 저장\n",
    "        plt.imsave(os.path.join(FOLDERS['visuals'], f'verify_{cls}_masked.png'), img_vis)\n",
    "        plt.imsave(os.path.join(FOLDERS['visuals'], f'verify_{cls}_aug.png'), np.array(img_aug))\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 실행\n",
    "verify_preprocessing_with_aug()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655a6072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 4] 모델 생성 팩토리 클래스 정의\n",
    "\n",
    "class ModelFactory:\n",
    "    @staticmethod\n",
    "    def get_model(model_name, num_classes):\n",
    "        \n",
    "        if model_name == 'resnet50':\n",
    "            model = models.resnet50(weights='DEFAULT')\n",
    "            model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "        elif model_name == 'densenet121':\n",
    "            model = models.densenet121(weights='DEFAULT')\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "        elif model_name == 'densenet169':\n",
    "            model = models.densenet169(weights='DEFAULT')\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "        elif model_name == 'densenet161':\n",
    "            model = models.densenet161(weights='DEFAULT')\n",
    "            model.classifier = nn.Linear(model.classifier.in_features, num_classes)\n",
    "            \n",
    "        else:\n",
    "            raise ValueError(f\"Unknown model: {model_name}\")\n",
    "        \n",
    "        return model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96287708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 5] 모델 학습 및 상세 지표 CSV 저장 (안전한 중간 저장 기능 추가)\n",
    "# 설명: 모델별로 학습이 끝날 때마다 개별 CSV를 저장하여, 중간에 끊겨도 기록을 보존합니다.\n",
    "\n",
    "def train_and_log_models(epochs):\n",
    "    print(f\"\\n=== 정밀 마스킹 모델 학습 시작 (Epochs: {epochs}) ===\")\n",
    "    \n",
    "    models_list = ['resnet50', 'densenet121', 'densenet169', 'densenet161']\n",
    "    \n",
    "    # 전체 기록을 담을 리스트 (마지막 통합 저장용)\n",
    "    all_history = []\n",
    "    \n",
    "    overall_pbar = tqdm(models_list, desc=\"Total Progress\", position=0)\n",
    "    \n",
    "    for name in overall_pbar:\n",
    "        print(f\"\\n>> Training Model: {name}\")\n",
    "        \n",
    "        # [NEW] 현재 모델의 기록만 담을 리스트 (개별 저장용)\n",
    "        model_history = []\n",
    "        # ModelFactory, class_names, DEVICE 등은 이전 셀에서 정의된 전역 변수 사용\n",
    "        model = ModelFactory.get_model(name, len(class_names))\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "        \n",
    "        # 스케줄러 정의\n",
    "        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs, eta_min=1e-6)\n",
    "        \n",
    "        best_f1 = 0.0\n",
    "        \n",
    "        for ep in range(epochs):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # --- Train ---\n",
    "            model.train()\n",
    "            running_train_loss = 0.0\n",
    "\n",
    "            # dataloaders는 이전 셀에서 정의된 전역 변수 사용\n",
    "            for inputs, labels in tqdm(dataloaders['train'], desc=f\"Ep {ep+1}\", leave=False):\n",
    "                inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                optimizer.zero_grad()\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                running_train_loss += loss.item() * inputs.size(0)\n",
    "            \n",
    "            # 스케줄러 업데이트 및 LR 기록\n",
    "            scheduler.step()\n",
    "            current_lr = optimizer.param_groups[0]['lr']\n",
    "            \n",
    "            epoch_train_loss = running_train_loss / len(dataloaders['train'].dataset)\n",
    "            \n",
    "            # --- Valid ---\n",
    "            model.eval()\n",
    "            running_valid_loss = 0.0\n",
    "            all_preds, all_labels = [], []\n",
    "            with torch.no_grad():\n",
    "                for inputs, labels in dataloaders['valid']:\n",
    "                    inputs, labels = inputs.to(DEVICE), labels.to(DEVICE)\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    running_valid_loss += loss.item() * inputs.size(0)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    all_preds.extend(preds.cpu().numpy())\n",
    "                    all_labels.extend(labels.cpu().numpy())\n",
    "            \n",
    "            epoch_valid_loss = running_valid_loss / len(dataloaders['valid'].dataset)\n",
    "            \n",
    "            # Metrics\n",
    "            acc = accuracy_score(all_labels, all_preds)\n",
    "            precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average='weighted', zero_division=0)\n",
    "            \n",
    "            cm = confusion_matrix(all_labels, all_preds)\n",
    "            TP = np.trace(cm); FP = cm.sum(axis=0) - np.diag(cm)\n",
    "            FN = cm.sum(axis=1) - np.diag(cm); TN = cm.sum() - (FP + FN + TP)\n",
    "            TP, FP, FN, TN = int(TP), int(FP.sum()), int(FN.sum()), int(TN.sum())\n",
    "\n",
    "            duration = time.time() - start_time\n",
    "            print(f\"Ep {ep+1}/{epochs} | LR: {current_lr:.6f} | T-Loss: {epoch_train_loss:.4f} | V-Loss: {epoch_valid_loss:.4f} | Acc: {acc:.4f} | F1: {f1:.4f} | Time: {duration:.1f}s\")\n",
    "            \n",
    "            # 기록 데이터 생성 -> 별도의 셀에서 csv 파일의 결과값들을 사용하여 그래프로 표현.\n",
    "            record = {\n",
    "                'model': name, 'epoch': ep + 1, 'learning_rate': current_lr,\n",
    "                'train_loss': epoch_train_loss, 'valid_loss': epoch_valid_loss,\n",
    "                'TP': TP, 'TN': TN, 'FP': FP, 'FN': FN,\n",
    "                'Accuracy': acc, 'Precision': precision, 'Recall': recall, 'F1_score': f1,\n",
    "                'Time_sec': duration\n",
    "            }\n",
    "            \n",
    "            model_history.append(record) # 개별 리스트에 추가\n",
    "            all_history.append(record)   # 전체 리스트에 추가\n",
    "            \n",
    "            if f1 > best_f1:\n",
    "                best_f1 = f1\n",
    "                torch.save(model.state_dict(), os.path.join(FOLDERS['results'], f'best_{name}.pth'))\n",
    "        \n",
    "        # [NEW] 모델 하나가 끝날 때마다 개별 CSV 저장\n",
    "        df_model = pd.DataFrame(model_history)\n",
    "        model_csv_path = os.path.join(FOLDERS['results'], f'metrics_{name}.csv')\n",
    "        df_model.to_csv(model_csv_path, index=False)\n",
    "        print(f\">> [저장 완료] {name} 학습 기록 저장됨: {model_csv_path}\")\n",
    "\n",
    "        # --- [VRAM 초기화 강화 섹션] ---\n",
    "        # 1. 모델과 관련된 모든 객체 참조 끊기\n",
    "        try:\n",
    "            del model\n",
    "            del optimizer\n",
    "            del criterion\n",
    "            del scheduler\n",
    "            if 'inputs' in locals(): del inputs\n",
    "            if 'labels' in locals(): del labels\n",
    "            if 'outputs' in locals(): del outputs\n",
    "        except NameError:\n",
    "            pass\n",
    "\n",
    "        # 2. Python 가비지 컬렉션 강제 실행\n",
    "        gc.collect() \n",
    "\n",
    "        # 3. PyTorch의 CUDA 캐시 비우기 (GPU 메모리 해제)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "            torch.cuda.synchronize() # 모든 스트림의 작업이 끝날 때까지 대기하여 확실히 비움\n",
    "            \n",
    "        print(f\">> {name} Finished. Best F1: {best_f1:.4f} (VRAM Cleared)\")\n",
    "        print(\"-\" * 80)\n",
    "\n",
    "    # 마지막에 전체 통합 파일도 저장 (분석용)\n",
    "    df_all = pd.DataFrame(all_history)\n",
    "    all_csv_path = os.path.join(FOLDERS['results'], 'metrics_all_details.csv')\n",
    "    df_all.to_csv(all_csv_path, index=False)\n",
    "    print(f\"\\n>> [최종 저장] 모든 모델 통합 기록 저장됨: {all_csv_path}\")\n",
    "\n",
    "# 실행\n",
    "train_and_log_models(epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179d96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 6] 학습 결과의 그래프 시각화 (스타일 적용 & 안전성 강화)\n",
    "# 각 모델별 Train/Valid Loss, F1-score, 누적 시간 비교\n",
    "\n",
    "import matplotlib.ticker as ticker\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_metrics_comparison_2x2_styled():\n",
    "    # 비교할 모델 리스트\n",
    "    models = ['resnet50', 'densenet121', 'densenet169', 'densenet161']\n",
    "    \n",
    "    # 개별 CSV 파일들을 읽어서 하나로 합치기\n",
    "    df_list = []\n",
    "    print(\">> 데이터 로드 중...\")\n",
    "    \n",
    "    for name in models:\n",
    "        csv_path = os.path.join(FOLDERS['results'], f'metrics_{name}.csv')\n",
    "        if os.path.exists(csv_path):\n",
    "            df = pd.read_csv(csv_path)\n",
    "            df_list.append(df)\n",
    "            print(f\"   - {name}: 로드 완료 ({len(df)} Epochs)\")\n",
    "        else:\n",
    "            print(f\"   - {name}: 파일 없음 (Skipping)\")\n",
    "            \n",
    "    if not df_list:\n",
    "        print(\"!! 로드할 데이터가 없습니다. 학습을 먼저 실행하세요.\")\n",
    "        return\n",
    "\n",
    "    # 데이터프레임 통합\n",
    "    df_all = pd.concat(df_list, ignore_index=True)\n",
    "    \n",
    "    # 누적 시간(Cumulative Time) 계산\n",
    "    # Time_sec가 에포크별 시간이므로, 누적합(cumsum)을 구해야 총 학습 시간이 됨\n",
    "    df_all['Cumulative_Time'] = df_all.groupby('model')['Time_sec'].cumsum()\n",
    "    \n",
    "    # [수정] 데이터 기반 최대 에포크 확인 (EPOCHS 변수 의존성 제거)\n",
    "    max_epoch = df_all['epoch'].max()\n",
    "    \n",
    "    # 2행 2열 그래프 생성\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 그래프 배치 설정 (행, 열, CSV컬럼명, 제목, Y축라벨)\n",
    "    plots_config = [\n",
    "        (0, 0, 'train_loss',      'Train Loss',           'Loss'),\n",
    "        (0, 1, 'valid_loss',      'Valid Loss',           'Loss'),\n",
    "        (1, 0, 'F1_score',        'Validation F1-score',  'F1-score'),     \n",
    "        (1, 1, 'Cumulative_Time', 'Cumulative Training Time', 'Time (sec)') \n",
    "    ]\n",
    "    \n",
    "    # 라벨창 스타일 지정 (가시성 강화)\n",
    "    styles = {\n",
    "        'resnet50':    {'marker': 's', 'linestyle': '--', 'color': 'navy',   'label': 'ResNet50'},\n",
    "        'densenet121': {'marker': '^', 'linestyle': '-',  'color': 'orange', 'label': 'DenseNet121'},\n",
    "        'densenet169': {'marker': 'D', 'linestyle': '-',  'color': 'red',    'label': 'DenseNet169'},\n",
    "        'densenet161': {'marker': 'o', 'linestyle': '-',  'color': 'brown',  'label': 'DenseNet161'}\n",
    "    }\n",
    "\n",
    "    print(\">> 그래프 생성 시작...\")\n",
    "\n",
    "    # 데이터 플로팅\n",
    "    for name in models:\n",
    "        df = df_all[df_all['model'] == name]\n",
    "        if df.empty: continue\n",
    "\n",
    "        st = styles.get(name, {'marker': 'o', 'linestyle': '-', 'color': 'black'})\n",
    "        \n",
    "        for r, c, col_name, title, ylabel in plots_config:\n",
    "            ax = axes[r, c]\n",
    "            ax.plot(df['epoch'], df[col_name], \n",
    "                    marker=st['marker'], \n",
    "                    linestyle=st['linestyle'],\n",
    "                    color=st['color'],\n",
    "                    label=st.get('label', name), \n",
    "                    linewidth=2,\n",
    "                    alpha=0.8)\n",
    "\n",
    "    # 라벨창 스타일 그리기 (가시성 강화)\n",
    "    for r, c, col_name, title, ylabel in plots_config:\n",
    "        ax = axes[r, c]\n",
    "        \n",
    "        # 타이틀 및 라벨\n",
    "        ax.set_title(title, fontsize=22, fontweight='bold', pad=20)\n",
    "        ax.set_xlabel('Epochs', fontsize=20, fontweight='bold', labelpad=10)\n",
    "        ax.set_ylabel(ylabel, fontsize=20, fontweight='bold', labelpad=10)\n",
    "\n",
    "        # Y축 범위 설정 추가 구간]\n",
    "        if 'Loss' in ylabel:            # Loss 그래프 공통 (Train & Valid)\n",
    "            ax.set_ylim(-0.02, 0.62)\n",
    "        elif 'F1-score' in ylabel:      # F1-score 그래프\n",
    "            ax.set_ylim(0.79, 1.01)\n",
    "\n",
    "        #  눈금 설정\n",
    "        ax.tick_params(axis='both', which='major', labelsize=14, pad=10, width=2)\n",
    "        for label in ax.get_xticklabels() + ax.get_yticklabels():\n",
    "            label.set_fontweight('bold')\n",
    "        \n",
    "        # 그리드 및 테두리\n",
    "        ax.grid(True, alpha=0.3, linestyle='--', linewidth=1.5)\n",
    "        for spine in ax.spines.values():\n",
    "            spine.set_linewidth(2)\n",
    "\n",
    "        # 범례 위치 로직\n",
    "        if 'Loss' in title:   # 1행 (Loss) -> 우측 상단\n",
    "            legend_loc = 'upper right'\n",
    "        elif 'F1' in title:   # 2행 1열 (F1) -> 우측 하단\n",
    "            legend_loc = 'lower right'\n",
    "        else:                 # 2행 2열 (Time) -> 좌측 상단\n",
    "            legend_loc = 'upper left'\n",
    "\n",
    "        ax.legend(fontsize=14, loc=legend_loc, prop={'weight':'bold', 'size':14})\n",
    "\n",
    "        # x축 간격 설정 (5단위)\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(5))\n",
    "        \n",
    "        # [수정] x축 범위 (데이터 기반)\n",
    "        ax.set_xlim(0, max_epoch + 1) \n",
    "\n",
    "        # Y축 범위 설정 (Time은 0부터)\n",
    "        if 'Time' in title:\n",
    "            ax.set_ylim(bottom=0) \n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(hspace=0.4, wspace=0.3) # 간격 조정\n",
    "    \n",
    "    # 저장 및 출력\n",
    "    save_path = os.path.join(FOLDERS['results'], 'metrics_comparison_2x2_styled.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\">> 그래프 저장 완료: {save_path}\")\n",
    "\n",
    "# 실행\n",
    "plot_metrics_comparison_2x2_styled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea22714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 7] Confusion Matrix 시각화 (2x2 Grid)\n",
    "# Actual vs Predicted\n",
    "# 설명: 저장된 Best 모델(pth)을 불러와 Test 셋에 대해 추론하고, Confusion Matrix를 2행 2열로 그려서 비교합니다.\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import platform # [추가] 시스템 확인용\n",
    "from matplotlib import rc\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score # [추가] f1_score\n",
    "\n",
    "# --- 한글 폰트 설정 함수 ---\n",
    "def set_korean_font():\n",
    "    system_name = platform.system()\n",
    "    try:\n",
    "        if system_name == 'Windows':\n",
    "            rc('font', family='Malgun Gothic')\n",
    "        elif system_name == 'Darwin': \n",
    "            rc('font', family='AppleGothic')\n",
    "        else: \n",
    "            # Colab 등 리눅스 환경 고려\n",
    "            rc('font', family='NanumBarunGothic') \n",
    "    except:\n",
    "        print(\"Warning: 폰트 설정에 실패했습니다. 기본 폰트를 사용합니다.\")\n",
    "    \n",
    "    plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "set_korean_font()\n",
    "\n",
    "def plot_confusion_matrices_final_v3():\n",
    "    print(\">> Confusion Matrix 시각화 시작...\")\n",
    "    \n",
    "    # 2x2 배치 설정 (리스트 사이에 쉼표(,) 추가 필수)\n",
    "    grid_models = [\n",
    "        ['densenet121', 'densenet161'],\n",
    "        ['densenet169', 'resnet50']\n",
    "    ]\n",
    "    \n",
    "    # 컬러맵 설정\n",
    "    cmaps = [\n",
    "        ['Oranges', 'Oranges'],\n",
    "        ['Oranges', 'Blues']  \n",
    "    ]\n",
    "    \n",
    "    # 모델명 매핑\n",
    "    model_pretty_names = {\n",
    "        'resnet50': 'ResNet50',\n",
    "        'densenet121': 'DenseNet121',\n",
    "        'densenet169': 'DenseNet169',\n",
    "        'densenet161': 'DenseNet161'\n",
    "    }\n",
    "    \n",
    "    # 라벨 매핑 (Normal -> Malignant -> Benign 순서 정렬)\n",
    "    target_order = ['Normal', 'Malignant', 'Benign']\n",
    "    display_names = {\n",
    "        'Normal': 'Normal (정상)',\n",
    "        'Malignant': 'Malignant (악성)',\n",
    "        'Benign': 'Benign (양성)'\n",
    "    }\n",
    "    \n",
    "    # 클래스 이름 매칭 로직\n",
    "    reorder_idx = []\n",
    "    final_display_labels = []\n",
    "    \n",
    "    # class_names가 정의되어 있는지 확인\n",
    "    current_class_names = class_names if 'class_names' in globals() else ['Benign', 'Malignant', 'Normal']\n",
    "\n",
    "    for target in target_order:\n",
    "        found = [name for name in current_class_names if target.lower() in name.lower()]\n",
    "        if found:\n",
    "            original_name = found[0]\n",
    "            reorder_idx.append(current_class_names.index(original_name))\n",
    "            final_display_labels.append(display_names[target])\n",
    "    \n",
    "    # 매칭 실패 시 기본값 사용\n",
    "    if len(reorder_idx) != 3:\n",
    "        reorder_idx = range(len(current_class_names))\n",
    "        final_display_labels = current_class_names\n",
    "\n",
    "    # 정답 데이터 로드 (Test Set 전체)\n",
    "    # Test Loader는 shuffle=False여야 순서가 보장됨\n",
    "    y_true_raw = []\n",
    "    for _, y in dataloaders['test']:\n",
    "        y_true_raw.extend(y.numpy())\n",
    "    y_true_raw = np.array(y_true_raw)\n",
    "    \n",
    "    # 그래프 생성\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 16))\n",
    "    \n",
    "    for row in range(2):\n",
    "        for col in range(2):\n",
    "            model_name = grid_models[row][col]\n",
    "            cmap_name = cmaps[row][col]\n",
    "            ax = axes[row][col]\n",
    "            \n",
    "            # 모델의 학습 영역 가중치 관련 *.pth 파일 경로 확인\n",
    "            pth_path = os.path.join(FOLDERS['results'], f'best_{model_name}.pth')\n",
    "            \n",
    "            if not os.path.exists(pth_path):\n",
    "                ax.text(0.5, 0.5, \"Model Not Found\", ha='center', va='center', fontsize=15)\n",
    "                ax.axis('off')\n",
    "                continue\n",
    "            \n",
    "            # 모델 로드 & 예측\n",
    "            # ModelFactory는 [Cell 3]에서 정의됨\n",
    "            try:\n",
    "                model = ModelFactory.get_model(model_name, len(current_class_names))\n",
    "                model.load_state_dict(torch.load(pth_path, map_location=DEVICE))\n",
    "                model.eval()\n",
    "                model.to(DEVICE)\n",
    "                \n",
    "                y_pred_raw = []\n",
    "                with torch.no_grad():\n",
    "                    for x, _ in dataloaders['test']:\n",
    "                        x = x.to(DEVICE)\n",
    "                        out = model(x)\n",
    "                        y_pred_raw.extend(out.argmax(1).cpu().numpy())\n",
    "                \n",
    "                # 혼동 행렬 계산\n",
    "                cm_raw = confusion_matrix(y_true_raw, y_pred_raw)\n",
    "                # 순서 재배치 (Numpy indexing)\n",
    "                cm_ordered = cm_raw[np.ix_(reorder_idx, reorder_idx)]\n",
    "                row_sums = cm_ordered.sum(axis=1)\n",
    "                \n",
    "                # 히트맵 그리기\n",
    "                sns.heatmap(cm_ordered, annot=False, fmt='', cmap=cmap_name, ax=ax,\n",
    "                            xticklabels=final_display_labels, \n",
    "                            yticklabels=final_display_labels, \n",
    "                            cbar=False, \n",
    "                            square=True, \n",
    "                            linewidths=1, linecolor='lightgray')\n",
    "                \n",
    "                # 텍스트 추가 (개수 및 비율)\n",
    "                for i in range(cm_ordered.shape[0]):\n",
    "                    for j in range(cm_ordered.shape[1]):\n",
    "                        count = cm_ordered[i, j]\n",
    "                        total_actual = row_sums[i]\n",
    "                        ratio = (count / total_actual * 100) if total_actual > 0 else 0\n",
    "                        text_val = f\"{count}\\n({ratio:.1f}%)\"\n",
    "                        \n",
    "                        # 글자색 자동 조정 (배경색에 따라)\n",
    "                        text_color = \"black\"\n",
    "                        if count == 0: \n",
    "                            text_color = \"red\" \n",
    "                        elif count > cm_ordered.max() * 0.5: \n",
    "                            text_color = \"white\"\n",
    "                            \n",
    "                        ax.text(j + 0.5, i + 0.5, text_val, \n",
    "                                ha=\"center\", va=\"center\", \n",
    "                                color=text_color, fontsize=16, fontweight='bold')\n",
    "\n",
    "                # Y축 역순 (Top-Down)\n",
    "                ax.invert_yaxis()\n",
    "                \n",
    "                # 스타일 조정\n",
    "                ax.tick_params(axis='x', pad=10) \n",
    "                ax.tick_params(axis='y', pad=10)\n",
    "                \n",
    "                ax.set_yticklabels(final_display_labels, rotation=90, va='center', fontsize=14, fontweight='bold')\n",
    "                ax.set_xticklabels(final_display_labels, rotation=0, ha='center', fontsize=14, fontweight='bold')\n",
    "                \n",
    "                ax.set_xlabel(\"Predicted cases\", fontsize=20, fontweight='bold', labelpad=20)\n",
    "                ax.set_ylabel(\"Actual cases\", fontsize=20, fontweight='bold', labelpad=20)\n",
    "                \n",
    "                # 타이틀 (Accuracy, F1 포함)\n",
    "                acc = accuracy_score(y_true_raw, y_pred_raw)\n",
    "                f1 = f1_score(y_true_raw, y_pred_raw, average='weighted')\n",
    "                display_name = model_pretty_names.get(model_name, model_name)\n",
    "                \n",
    "                ax.set_title(f\"{display_name}\\n(Acc: {acc:.2%} | F1: {f1:.3f})\", \n",
    "                             fontsize=20, fontweight='bold', pad=20)\n",
    "                \n",
    "                # 메모리 정리\n",
    "                del model\n",
    "                torch.cuda.empty_cache()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {model_name}: {e}\")\n",
    "                ax.text(0.5, 0.5, \"Error Loading Model\", ha='center', va='center', fontsize=15)\n",
    "                ax.axis('off')\n",
    "\n",
    "    # 간격 조정 및 저장\n",
    "    plt.tight_layout()\n",
    "    plt.subplots_adjust(wspace=0.4, hspace=0.4)\n",
    "    \n",
    "    save_path = os.path.join(FOLDERS['results'], 'confusion_matrices_final_v3.png')\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.show()\n",
    "    print(f\">> 그래프 저장 완료: {save_path}\")\n",
    "\n",
    "# 실행\n",
    "plot_confusion_matrices_final_v3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4257261b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [Cell 8] Grad-CAM 전체 이미지 시각화 (Green/Red Text & Yellow Boundary)\n",
    "# 설명: 모든 모델에 대해 모든 Test 이미지를 Grad-CAM으로 시각화합니다.\n",
    "\n",
    "# Green Text: 정답 일치\n",
    "# Red Text: 정답 불일치 (오답)\n",
    "# Yellow Boundary: 전처리 단계에서 검출된 몸통 라인 표시\n",
    "# Grad-CAM: 모델이 집중한 부위 (무지개색 히트맵, 붉은색 : 높음, 파란색 : 낮음)\n",
    "\n",
    "#====================================\n",
    "# 최소 한번 설치 후 주석처리 요망.\n",
    "#!pip install grad-cam\n",
    "#====================================\n",
    "\n",
    "import gc\n",
    "import cv2\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# --- Grad-CAM Hook Class (메모리 최적화 버전) ---\n",
    "class SimpleGradCAM:\n",
    "    def __init__(self, model, target_layer):\n",
    "        self.model = model\n",
    "        self.handlers = []\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        # Inplace 연산 에러 방지\n",
    "        for m in self.model.modules():\n",
    "            if hasattr(m, 'inplace'): m.inplace = False\n",
    "            \n",
    "        def forward_hook(module, input, output):\n",
    "            self.activations = output\n",
    "            output.register_hook(self.save_grads)\n",
    "        self.handlers.append(target_layer.register_forward_hook(forward_hook))\n",
    "\n",
    "    def save_grads(self, grad): self.gradients = grad\n",
    "\n",
    "    def generate(self, input_tensor, target_label):\n",
    "        self.model.zero_grad()\n",
    "        output = self.model(input_tensor)\n",
    "        \n",
    "        # [메모리 최적화] retain_graph=True 제거 -> VRAM 누수 방지\n",
    "        output[0, target_label].backward() \n",
    "        \n",
    "        # 데이터 추출 후 즉시 CPU로 이동 및 Detach\n",
    "        grads = self.gradients.detach().cpu().numpy()[0]\n",
    "        acts = self.activations.detach().cpu().numpy()[0]\n",
    "        \n",
    "        # VRAM에서 참조 해제\n",
    "        self.gradients = None\n",
    "        self.activations = None\n",
    "        \n",
    "        weights = np.mean(grads, axis=(1, 2))\n",
    "        cam = np.zeros(acts.shape[1:], dtype=np.float32)\n",
    "        for i, w in enumerate(weights): cam += w * acts[i, :, :]\n",
    "        \n",
    "        cam = np.maximum(cam, 0)\n",
    "        \n",
    "        # [수정됨] 해상도 하드코딩(224) 제거 -> IMG_SIZE(448)로 변경\n",
    "        # IMG_SIZE 변수가 없다면 448로 기본값 설정\n",
    "        target_size = size if 'size' in globals() else input_tensor.shape[2]\n",
    "        cam = cv2.resize(cam, (target_size, target_size))\n",
    "        \n",
    "        cam = (cam - np.min(cam)) / (np.max(cam) - np.min(cam) + 1e-10)\n",
    "        \n",
    "        pred_idx = output.argmax(dim=1).item()\n",
    "        \n",
    "        # 출력 텐서 삭제\n",
    "        del output\n",
    "        return cam, pred_idx\n",
    "    \n",
    "    def close(self):\n",
    "        for h in self.handlers: h.remove()\n",
    "        self.handlers = []\n",
    "\n",
    "# --- 통합 시각화 함수 ---\n",
    "def visualize_gradcam_safe_with_box():\n",
    "    print(\">> [분석 모드] Grad-CAM + 암 의심 영역(Pink Box) 시각화 시작...\")\n",
    "    \n",
    "    models_list = ['resnet50', 'densenet121', 'densenet169', 'densenet161']\n",
    "    test_ds = dataloaders['test'].dataset\n",
    "    \n",
    "    def denormalize(tensor):\n",
    "        mean, std = np.array([0.485, 0.456, 0.406]), np.array([0.229, 0.224, 0.225])\n",
    "        img = tensor.permute(1, 2, 0).cpu().numpy()\n",
    "        return np.clip(img * std + mean, 0, 1)\n",
    "\n",
    "    # [Helper] 히트맵에서 가장 뜨거운 영역(Attention Box) 찾기\n",
    "    def get_attention_box(cam_mask, threshold=0.7):\n",
    "        # 상위 30% 강도 이상인 부분 추출\n",
    "        _, thresh = cv2.threshold(cam_mask, threshold, 1, cv2.THRESH_BINARY)\n",
    "        thresh = np.uint8(thresh * 255)\n",
    "        contours, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        if contours:\n",
    "            c = max(contours, key=cv2.contourArea) # 가장 큰 덩어리\n",
    "            return cv2.boundingRect(c) # x, y, w, h\n",
    "        return None\n",
    "\n",
    "    cols, rows = 6, 4\n",
    "    num_imgs = len(test_ds)\n",
    "    \n",
    "    # tqdm으로 전체 페이지 진행률 표시\n",
    "    page_iterator = tqdm(range(0, num_imgs, cols), desc=\"Generating Pages\")\n",
    "    \n",
    "    for start_idx in page_iterator:\n",
    "        end_idx = min(start_idx + cols, num_imgs)\n",
    "        batch_len = end_idx - start_idx\n",
    "        \n",
    "        # 그림판 생성 (4행 6열)\n",
    "        fig, axes = plt.subplots(rows, cols, figsize=(24, 18)) \n",
    "        plt.subplots_adjust(hspace=0.4, wspace=0.3)\n",
    "        \n",
    "        for m_idx, name in enumerate(models_list):\n",
    "            try:\n",
    "                # 모델 로드 (필요할 때만 로드하고 바로 삭제)\n",
    "                pth_path = os.path.join(FOLDERS['results'], f'best_{name}.pth')\n",
    "                if not os.path.exists(pth_path): continue\n",
    "                \n",
    "                model = ModelFactory.get_model(name, len(class_names))\n",
    "                model.load_state_dict(torch.load(pth_path, map_location=DEVICE))\n",
    "                model.eval()\n",
    "                \n",
    "                target = model.layer4[-1] if 'resnet' in name else model.features.norm5\n",
    "                cam_tool = SimpleGradCAM(model, target)\n",
    "                \n",
    "                for i in range(batch_len):\n",
    "                    idx = start_idx + i\n",
    "                    img_tensor, label = test_ds[idx]\n",
    "                    input_tensor = img_tensor.unsqueeze(0).to(DEVICE)\n",
    "                    \n",
    "                    # Grad-CAM 생성\n",
    "                    mask, pred = cam_tool.generate(input_tensor, label)\n",
    "                    \n",
    "                    # 이미지 합성 (CPU 연산)\n",
    "                    img_rgb = denormalize(img_tensor)\n",
    "                    img_uint8 = np.uint8(255 * img_rgb)\n",
    "                    \n",
    "                    heatmap = cv2.applyColorMap(np.uint8(255 * mask), cv2.COLORMAP_JET)\n",
    "                    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)\n",
    "                    \n",
    "                    # [중요] 크기 불일치 방지용 리사이즈 (혹시 모를 오차 대비)\n",
    "                    if heatmap.shape[:2] != img_rgb.shape[:2]:\n",
    "                        heatmap = cv2.resize(heatmap, (img_rgb.shape[1], img_rgb.shape[0]))\n",
    "                    \n",
    "                    overlay = (heatmap.astype(float)/255 + img_rgb) / 2\n",
    "                    final_vis = np.uint8(255 * overlay).copy()\n",
    "\n",
    "                    # ---------------------------------------------------------\n",
    "                    # [시각화] 노란색 몸통 라인 (Yellow Line)\n",
    "                    # ---------------------------------------------------------\n",
    "                    gray_crop = cv2.cvtColor(img_uint8, cv2.COLOR_RGB2GRAY)\n",
    "                    _, thresh = cv2.threshold(gray_crop, 10, 255, cv2.THRESH_BINARY)\n",
    "                    contours_body, _ = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "                    \n",
    "                    if contours_body:\n",
    "                        c_body = max(contours_body, key=cv2.contourArea)\n",
    "                        cv2.drawContours(final_vis, [c_body], -1, (255, 255, 0), 2) # Yellow\n",
    "\n",
    "                    # ---------------------------------------------------------\n",
    "                    # [시각화] 암 의심 영역 박스 (Pink Box)\n",
    "                    # ---------------------------------------------------------\n",
    "                    # box = get_attention_box(mask)\n",
    "                    # if box:\n",
    "                    #    bx, by, bw, bh = box\n",
    "                    #    cv2.rectangle(final_vis, (bx, by), (bx+bw, by+bh), (255, 0, 255), 2) # Pink\n",
    "\n",
    "                    # ---------------------------------------------------------\n",
    "                    # 그래프 그리기\n",
    "                    # ---------------------------------------------------------\n",
    "                    ax = axes[m_idx, i]\n",
    "                    ax.imshow(final_vis)\n",
    "                    \n",
    "                    color = 'green' if label == pred else 'red'\n",
    "                    fname = os.path.basename(test_ds.samples[idx][0])\n",
    "                    \n",
    "                    title_text = f\"[{name}]\\nAct: {class_names[label]}\\nPred: {class_names[pred]}\"\n",
    "                    ax.set_title(title_text, color=color, fontsize=14, fontweight='bold')\n",
    "                    \n",
    "                    ax.set_xlabel(fname, fontsize=12)\n",
    "                    ax.set_xticks([]); ax.set_yticks([])\n",
    "                    \n",
    "                    del input_tensor\n",
    "                \n",
    "                # 모델별 루프 종료 후 정리\n",
    "                cam_tool.close()\n",
    "                del model, cam_tool\n",
    "                torch.cuda.empty_cache() # VRAM 비우기\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"!! Error processing {name}: {e}\")\n",
    "                torch.cuda.empty_cache()\n",
    "            \n",
    "        # 빈 칸 처리\n",
    "        if batch_len < cols:\n",
    "            for i in range(batch_len, cols):\n",
    "                for j in range(rows): axes[j, i].axis('off')\n",
    "        \n",
    "        # 페이지 저장\n",
    "        page = start_idx // cols + 1\n",
    "        save_path = os.path.join(FOLDERS['gradcam'], f'GradCAM_Box_Page_{page:03d}.png')\n",
    "        plt.savefig(save_path, bbox_inches='tight', dpi=150)\n",
    "        \n",
    "        # [중요] 메모리 완전 해제\n",
    "        plt.clf()\n",
    "        plt.close('all')\n",
    "        gc.collect() \n",
    "        \n",
    "        # tqdm 업데이트\n",
    "        page_iterator.set_postfix({'Last Saved': f'Page {page}'})\n",
    "\n",
    "# 실행\n",
    "visualize_gradcam_safe_with_box()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d76d6f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
